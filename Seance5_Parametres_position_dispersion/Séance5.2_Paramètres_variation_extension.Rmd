---
title: "Séance 5.2: Paramètres de variation"
subtitle: "Extensions"
author: "Visseho Adjiwanou, PhD."
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  beamer_presentation:
    colortheme: beaver
    fonttheme: structurebold
    theme: AnnArbor
  slidy_presentation: default
  ioslides_presentation: default
---

## Plan de présentation

- Scores standardisés ou scores-Z
- Loi normale
- Distribution d'échantillonnage
- Théorème central limite
- Intervalles de confiances
- Application


## Scores standardisés ou scores-Z

- Un score standardisé mesure à combien d'écarts-types de la moyenne se situe un score donné
- Sa formule est :

$$ Z_i = \frac{X_i - \bar{X}}{s}$$

- $Z_i$ = le score standadisé du $i^e$ cas

- $X_i$ = le score du $i^e$ cas

- $\bar{X}$ = la moyenne

- s = l'écart-type

- Ils sont particulièrement utiles lorsque l'on compare des scores provenant de distribution dont les moyennes et les écarts-types sont différentes.


## Scores standardisés ou scores-Z

- Exemple: Qui de Bill avec un revenu de 80000 au Québec et Alice avec un revenu de 110000 à Alberta a le meilleu revenu dans sa province?

- Rappelons que 
  - le revenu moyen à Alberta 103446.28 est et l'ecart-type vaut 92722.25
  - le revenu moyen au Québec 71150.87 est et l'écart-type vaut 46601.69


## Scores standardisés ou scores-Z

- Calculons les scores standardisés de Bill et de Alice


```{r}

# Québec
Score_z_bill <- (80000 - 71150.87)/46601.69
Score_z_bill

# Alberta
Score_z_alice <- (110000 - 103446.28)/92722.25
Score_z_alice


```

- On voit que Bill a un revenu qui se situe à 0.19 écart type de la moyenne des revenus au Québec alors qu'Alice ne se trouve qu'à 0.07 écart-type. Donc, le revenu de Bill est meilleur que le revenu d'Alice.

## Exercice

Voici les scores de 6 individus:

Individu   Score (Xi) 
---------- ---------------
1          64
2          68
3          70
4          71
5          69
6          66

1. Calculer les scores sstandardisés (Zi) de chaque individu
2. Calculer la moyenne des scores (Zi). Quelle conclusions tirez-vous?
3. Calculer l'écart-type des scores (Zi). Quelle conclusion tirez-vous?
4. Pouvez-vous démontrer les résultats obtenus au 2 et 3 à partir de la formule du score standardisé?


## Solution

```{r}

Score <- c(64, 68, 70, 71, 69, 66)
Score

Z_score <- (Score - mean(Score))/sd(Score)
Z_score

# Moyenne
mean(Z_score)

# Écart-type
sd(Z_score)

```

## La distribution normale

- La distribution normale est une distribution particulière, symétrique en forme de cloche
- Ce n'est pas toutes les distributions en forme de cloche qui sont normales
- Une distribution normale doit s'écrire sous la forme:

$$ Y = \frac{e^{-(x - \mu)^2/2\sigma^2}}{\sigma\sqrt{2\pi}}$$
- $\mu$ est la moyenne et $\sigma$ l'écart-type

- Elle est notée $N(\mu, \sigma)$


## La distribution normale

Voici deux distributions normales

```{r, echo=TRUE}

library(tidyverse)

courbe_normale <- 
  ggplot(data = data.frame(x = c(-5, 25)), aes(x)) +
  stat_function(fun = dnorm, args = list(mean = 5, sd = 3), color = "blue",
                xlim = c(-5, 15)) +
  stat_function(fun = dnorm, args = list(mean = 15, sd = 2), color = "green",
                xlim = c(5, 25))


courbe_normale


```

## La distribution normale: Propriété

![](Courbe_normale.png)

Quelque soit la forme de la loi normale:

1. L'intervalle d'un écart-type de part et d'autre de la moyenne contient 68% de la distribution

2. L'intervalle de deux écart-types de part et d'autre de la moyenne contient 95% de la distribution 

3. L'intervalle de trois écart-types de part et d'autre de la moyenne contient 99,7% de la distribution 
  
## Ecart-type correspondant à x pourcentage de la distribution

- Il est préférable de partir de l'intervalle de déterminer plus précisément le nombre d'écart-type qui délimite l'intervalle.

>- Par exemple, quel intervalle contient 60% de la distribution?

>- Autrement dit, comme la courbe est symétrique, on dira que 30% de la distribution se trouve entre la moyenne et la valeur recherchée. Donc que 20% se trouve au-delà.

>- Prob(distribution < v1) = 0.2 nous donne tout simplement la valeur de 20 ième percentile de la distribution

>- Prob(distribution < v2) = 0.8 dit que 80% de la distribution est inférieure à cette valeur. 

>- Donc l'intervalle [V1, V2] contient 60% (80% - 20%) de la distribution


## Ecart-type correspondant à x pourcentage de la distribution

On peut le calculer assez facilement avec la fonction qnorm.

```{r}

v1 <- qnorm(0.20, mean = 5, sd = 3)
v1

v2 <- qnorm(0.80, mean = 5, sd = 3)
v2

```

>- Ainsi, on trouve que l'intervalle en question est [2,47; 7,52] pour la distribution normale N(5, 3). 

>- Cet intervalle contient 60% de la distribution

## Ecart-type correspondant à x pourcentage de la distribution



```{r}

ggplot(data = data.frame(x = c(-5, 15)), aes(x)) +
  stat_function(fun = dnorm, args = list(mean = 5, sd = 3), color = "red") +
  stat_function(fun = dnorm, args = list(mean = 5, sd = 3),
                geom = "area", fill = "red", xlim = c(v1, v2), alpha = 0.2)

```



## Loi normale (centrée réduite)

- Calculer les quantiles pour différentes distributions normales peut être fastidieux (dans le temps). 
- Alors, les statisticiens ont calculé cela pour la distribution normale centrée réduite
- Lorsque la moyenne vaut 0 et l'écart-type vaut 1, on parle de distribution normale centrée réduite
- Vous comprenez donc que si vous standardisez les scores de votre distribution normale, vous trouvez une distribution normale centrée réduite

## Loi normale (centrée réduite)


```{r}

courbe_normale <- 
  ggplot(data = data.frame(x = c(-4, 4)), aes(x)) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 1), color = "blue") 

courbe_normale
?dnorm

```


## Loi normale (centrée réduite)


```{r, echo=FALSE}
ggplot(data = data.frame(x = c(-4, 4)), aes(x)) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 1), color = "red") +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 1), color = "blue",
                geom = "area", fill = "lightblue", xlim = c(-1, 1)) +
    stat_function(fun = dnorm, args = list(mean = 0, sd = 1), color = "green",
                geom = "area", fill = "green", xlim = c(-2, 2), alpha = 0.2)  

```

- On voit que 68% de la distribution est comprise entre -1 et 1 écart-type (vert foncé)
- On voit que 95% de la distribution est comprise entre -2 (-1.96) et 2 (1.96) écarts-types (vert clair) 

## Lecture du tableau de distribution

Voir livre


Distribution d'échantillonnage
=============================================

## Distribution d'échantillonnage

- Il est possible d'utiliser des distributions de données d'échantillon afin de décrire la population de laquelle fut tiré l'échantillon

- Une **distribution d'échantillonnage** (par exemple de la moyenne) est la distribution de l'ensemble des moyennes calculées sur l'ensemble des échantillons possibles de taille N qu'on peut tirer de cet échantillon


## Distribution d'échantillonnage

- Exemple simple

  - Voici les âges de 4 personnes {10, 11, 13, 14}
  - Voici les échantillons possibles de 3 personnes qu'on peut tirer de cette population:
  
>- (10, 11, 13) avec la moyenne de 11,3 ans
>- (10, 11, 14) avec la moyenne de 11,7 ans
>- (11, 13, 14) avec la moyenne de 12,7 ans

>- 11,3; 11,7 et 12,7 est appellé la distribution d'échantillonnage


## Distribution d'échantillonnage

https://www.alloprof.qc.ca/fr/eleves/bv/mathematiques/les-permutations-les-arrangements-et-les-combinai-m1346

- Exemple simple

- Voici les âges de 4 personnes {10, 11, 13, 14}
- Tirage sans remise de 3 personnes parmi 4: 4!/(4-3)!x3! = 4
- Tirage avec remise : (4+3-1)!/(4-3)!x3! = 6!/1!x3! = 120 

## Distribution d'échantillonnage - propriété

- A mesure qu'augmente la taille N de l'échantillon, la distribution d'échantillonnage de la moyenne s'apparente de plus en plus à une distribution normale, dont la moyenne est semblable à celle de la **population** et dont l'écart-type est de $\frac{\sigma}{\sqrt{N}}$

>- On nomme cela le **théorème de limite centrale**

>- L'écart-type de la distribution d'échantillonnage est appelé **erreur-type**

>- Il vaut: $\frac{\sigma}{\sqrt{N}}$

## Exemple

- Supposons que le salaire moyen issu d'un échantillon de 1000 Québécois vaut 65000$ et l'écart-type de 32000.

>- On dira que le salaire moyen des Québécois vaut 65000$. Mais, ce faisant on commet une ereur.

>- Si nous approximons aussi l'écart-type du salaire de la population par l'écart-type du salaire de l'échantillon, on peut alors dire que l'erreur-type vaut: 

>- 32000/racine_carré (1000) = 1012


Intervalle de confiance
======================================================

## Intervalle de confiance

- La meilleure estimation que nous pouvons avoir de la moyenne de la population est la moyenne de l'échantillon

>- Cependant, cette moyenne calculée à partir d'un seul échantillon peut être soit plus élevée, ou plus faible que la vraie moyenne de la population

>- Il parait donc extrêmement utile de déterminer l'intervalle, de part et d'autre de la moyenne, à l'intérieur duquel il est probable de trouver la moyenne de la population

>- L'erreur-type va nous aider à trouver cela

## Intervalle de confiance

Le théorème de la limite centrale nous permet de déterminer cette intervalle. 

>- On sait que plus N est grand, plus la distribution d'échantillonnge va suivre la distribution normale N(moyenne de l'échantillon, $\sigma/\sqrt(N)$)

>- On sait aussi que dans une distribution normale, 95% de la distribution se trouve à plus ou moins 2 écart-types de la moyenne (plus précisément à 1.96 écart-type)

>- Ainsi, l'intervalle de confiance à 95% sera déterminée par:

## Intervalle de confiance

$$ [\bar{X} - 1.96\sigma_{\bar{X}} , \bar{X} + 1.96\sigma_{\bar{X}}]$$

>- Dans l'exemple précédent, on dira que dans 95% des cas, le salaire moyen de la population Québécoise va se trouver dans l'intervalle [65000 - 1.96x1012, 65000 + 1.96x1012], soit [63016, 66983]

>- 1,96 est la valeur du score standardisé correspondant à l'intervalle de 95%


Théorème central limite - Règle de l'Approximation Normale (généralité)
============================================================================

## Dégré de fiabilité de l'échantillon

- Le but de l'échantillonnage aléatoire est d'éffectuer une inférence relative à la population sous-jacente.
- On souhaite que la moyenne de l'échantillon - $\bar{X}$ soit une estimation proche de la moyenne de la population - $\mu$.
- Deux façons d'étudier le degré d'approximation de $\mu$ par $\bar{X}$.

1. A partir de formules mathématiques
2. A partir de la distribution d'échantillonnage


## Moments de la moyenne de l'échantillon

- On démontre que :
- E($\bar{X}$) = $\mu$ : la moyenne de l'échantillonnage $\bar{X}$ coïncidera en moyenne avec l'objectif, ie. $\bar{X}$ égalisera $\mu$

- Erreur type d'échantillon (standard error) = SE = $\sigma_{\bar{X}}$ = $\frac{\sigma}{\sqrt{n}}$, où $\sigma$ est l'écart type dans la population

- L'erreur type de $\bar{X}$ diminue quand la taille de l'échantillon aléatoire augmente.

- Plus l'échantillon est grand, plus $\bar{X}$ donne une estimation exacte de la moyenne de la population.
  
- **NB**: Ne pas confondre:
- écart type (en anglais, standard deviation) et
- erreur type ou écart type d'échantillon (en anglais, standard error)


## Forme de la distribution d'échantillonnage


![](distribution_echantillonnage.jpg)




## Théorème central limite (Règle de l'Approximation Normale)


Dans les échantillons aléatoires de taille n, la moyenne de l'échantillon $\bar{X}$ varie autour de la moyenne de la population $\mu$ avec un écart type égal à $\frac{\sigma}{\sqrt{n}}$ (ou $\sigma$ est l'écart type de la population). 
Donc, quand n s'accroît, la distribution d'échantillonnage de $\bar{X}$ est de plus en plus concentrée autour de son objectif $\mu$. Elle devient de plus en plus proche de la distribution normale (forme de cloche).


## Théorème central limite (Règle de l'Approximation Normale)

![](tcl.jpg)



## Théorème de la limite centrale (Règle de l'Approximation Normale)

- Dire que la moyenne de l'échantillon $\bar{X}$ varie autour de la moyenne de la population $\mu$ avec une erreur type $\sigma_{\bar{X}}$ égale à $\frac{\sigma}{\sqrt{n}}$ revient à dire que la distribution $\bar{X}$ suit une loi normale de moyenne $\mu$ et d'écart type $\frac{\sigma}{\sqrt{n}}$

- $\bar{X}$ suit $N(\mu, \frac{\sigma}{\sqrt{n}})$

- Ou que ($\frac{(\bar{X}-\mu)}{\frac{\sigma}{\sqrt{n}}}$) suit une loi **normale dite centrée réduite** N(0,1)


## Théorème de la limite centrale (Règle de l'Approximation Normale) - Exemple

Une population d'étudiants d'un grand campus du Middle-West a une taille moyenne de $\mu$ = 175.26 cm (69 inches) et un écart type $\sigma$ = 8.18cm (3.22 inches). Si un échantillon aléatoire de n = 10 individus est prélevé, quelle est la probabilité pour que la moyenne de l'échantillon $\bar{X}$ s'écarte de 5.08 cm (2 inches) de la moyenne de la population?


```{r, echo=FALSE}

erreur_type <- 3.22/sqrt(10)
erreur_type
 

distribution <-
  ggplot(data = data.frame(x = c(64, 74)), aes(x)) +
  stat_function(fun = dnorm, args = list(mean = 69, sd = erreur_type), color = "blue") +
  geom_vline(aes(xintercept = 71, color = "red")) +
  geom_vline(aes(xintercept = 67, color = "green")) +
  theme(legend.position = "none")
distribution


```

## Théorème central limite (Règle de l'Approximation Normale) - Exemple

- **Réponse**:
- Selon la Règle de l'Approximation Normale, $\bar{X}$ est normalement distribuée avec:
- Espérance = $\mu$ = 69 et
- Écart type d'échantillon = $\sigma_{\bar{X}} = \frac{\sigma}{\sqrt{n}} = \frac{3.22}{\sqrt{10}}$ = 1.02

- On cherche à déterminer la probabilité que $\bar{X}$ s'écarte de 2 inches de $\mu$, c'est à dire qu'elle se trouve entre 67 et 71.
- Aussi, calcule-t-on, d'abord la probabilité que $\bar{X}$ soit supérieur à 71, en commençant par centrer et réduire: 

$$\text{Z = } \frac{\bar{X}-\mu}{\sigma_{\bar{X}}} = \frac{71 - 69}{1.02} = 1.96$$

- Cela signifie que la valeur critique de 71 pour que la moyenne de l'échantillon est environ de 2 écarts-type au dessus de son espérance 69.


## Théorème central limite (Règle de l'Approximation Normale) - Exemple

- D'après le tableau de la loi normale centrée réduite, on trouve que la probabilité que Z excède 1.96 est seulement de 0.025. C'est ce que montre la partie droite hachurée sur la figure (montrer la figure en classe).
- En raison de la symétrie de la distribution normale, l'extrémité gauche a la même probabilité 0.025.
- Ainsi, on peut déterminer la probabilité cherchée de la partie centrale : 
$Probabilité = 1.000 - 0.025 - 0.025 = 0.95$
- On conclut donc qu'il y a 95% de chance pour que la moyenne de l'échantillon s'écarte de 2 inches de la moyenne de la population


## Théorème central limite (Règle de l'Approximation Normale) - Question

1. Quelle est la probabilité que cette moyenne s'écarte de 1 inche de la moyenne de la population? Est-ce que cette probabilité va être plus grande ou plus pétite que la première? 
2. Quelle est la probabilité que cette moyenne s'écarte de 3 inches de la moyenne de la population? Est-ce que cette probabilité va être plus grande ou plus pétite que la première?

## FIN

<!--

Application
============================================================

## Introduction

Nous allons travailler avec les données `bm_results2012.txt` du marathon de Boston de 2012. Le tableau ci-dessous présente les informations contenues dans cette base de données.

Variables    Description
-----------  -----------------------
V1           Nom 
V2           Sexe
V3           Age
V4           Division
V5           Pays
V6           Temps mis


## Chargement de la base de données

```{r, out.width= '70%', out.height='70%', message=FALSE, warning=FALSE, error=FALSE}
rm(list = ls())
marathon <- read.csv("bm_results2012.txt", header = FALSE, quote = "")

```


## Distribution de la variable V6

- variable continue, on peut calculer les paramètres de tendance centrales et de dispersion

- Position

```{r}
# Moyenne
mean(marathon$V6)

# Mediane
median(marathon$V6)

# Mode

```

On voit que le marathon de Boston est couru en moyenne à 263 minutes. La moitié des coureurs sont arrivés avant 255.8 minutes alors que l'autre moitié est arrivé après. 

- Dispersion

```{r}
# variance
var(marathon$V6)

# Écart-type
sd(marathon$V6)
```

La variance égale 2502 minutes au carré alors que l'écrat-type vaut 50 minutes. On sait que la variance n'est pas de la même unité de mesure que la variable. C'est pourquoi on prend justement l'écart-type. En soit, ces mesure ne nous apporte pas beaucoup d'information. C'est en les comparant à une autre distribution qu'on peut tirer des conclusions. 

On peut mieux présenter ces résultats en utilisant tydyverse

```{r}

caract <- 
  marathon %>% 
  summarise(moyenne = mean(V6, na.rm = TRUE),
            ecarttype = sd(V6, na.rm = TRUE),
            mediane = median(V6, na.rm = TRUE),
            Q1 = quantile(V6, prob = 0.25),
            Q3 = quantile(V6, prob = 0.75),
            variance = var(V6, na.rm = TRUE))%>% 
  mutate(echantillon = factor("Echantillon S1"))

caract
```


## Représentation graphique

Il y a deux représentations qu'on fait d'une variable quantitative:
- l'histogramme
- la boite à moustache

1. Histogramme


```{r, out.width= '50%', message=FALSE, warning=FALSE, error=FALSE}

library(tidyverse)

fig1 <- 
  ggplot(marathon) +
  geom_histogram(aes(x = V6), color="black", fill="white") +
  geom_freqpoly(aes(x = V6), colour = "blue") +
  stat_function(fun = dnorm, args = list(mean = mean(marathon$V6), sd = sd(marathon$V6)), colour = "green") +
  geom_vline(aes(xintercept = mean(V6)), color = "red", linetype = "dashed") +
  labs(title = "Histogramme du Marathon de 2002",
       x = "Temps pour compléter le marathon",
       y = "Nombre de coureurs")


```


## Distribution de la variable V6

```{r, out.width= '90%', message=FALSE, warning=FALSE, error=FALSE}

fig1

```

## Boite à moustache

```{r}
class(marathon$V6)
fig2 <- 
  ggplot(marathon) +
  geom_boxplot(aes(y = V6)) +
  labs(title = "Diagramme de quartile",
       x = "",
       y = "Temps mis")

```


```{r}
fig2
```

Dans la plupart des cas, nous ne disposons pas de l'information de la population. Par exemple, pour estimer le revenu moyen de la population, nous devons disposer d'un échantillon. 

Échantillonnage aléatoire simple 
========================================================

## Échantillonnage aléatoire simple

On appelle échantillonnage aléatoire simple celui où chaque individu de la population **a la même chance d'être choisi** chaque fois que l'on tire une observation.

- Maintenant, prenons un échantillon de cette population et analysons ses caractéristiques

<div align="center">
```{r, out.width= '60%', out.height='70%', message=FALSE, warning=FALSE, error=FALSE}

set.seed(430)
marathon_S1 <- sample_n(marathon, 40, replace = FALSE)

head(marathon_S1)

``` 
</div>


## Échantillonnage aléatoire simple

```{r, out.width= '60%', out.height='70%', message=FALSE, warning=FALSE, error=FALSE}

ggplot(marathon_S1) +
  geom_histogram(aes(x = V6)) +
  labs(title = "Histogramme du Marathon de 2012",
       x = "Temps pour compléter le marathon",
       y = "Nombre de coureurs")

```


## Échantillonnage aléatoire simple

```{r, out.width= '70%', out.height='70%', message=FALSE, warning=FALSE, error=FALSE}

caract_S1 <- 
  marathon_S1 %>% 
  summarise(moyenne = mean(V6, na.rm = TRUE),
            ecarttype = sd(V6, na.rm = TRUE),
            mediane = median(V6, na.rm = TRUE),
            Q1 = quantile(V6, prob = 0.25),
            Q3 = quantile(V6, prob = 0.75),
            variance = var(V6, na.rm = TRUE))%>% 
  mutate(echantillon = factor("Echantillon S1"))

caract_S1

```


## Échantillonnage aléatoire simple - Comparaison de la moyenne d'échantillon et la moyenne de population

```{r, out.width= '70%', out.height='70%', message=FALSE, warning=FALSE, error=FALSE}

# Comparaison
caract_c <- bind_rows(caract, caract_S1)
caract_c

```


## Est-ce que cet échantillon est représentatif?

```{r, out.width= '50%', out.height='70%', message=FALSE, warning=FALSE, error=FALSE}

library(summarytools)

freq(marathon$V2)
freq(marathon_S1$V2)

```



Échantillonnage aléatoire simple - distribution d'échantillonnage
========================================================

## 100 échantillons de taille 10

```{r}

library(tidyverse)

```

- Ressource: https://stackoverflow.com/questions/42676348/multiple-random-sampling-in-r

```{r, out.width= '60%', out.height='70%', message=FALSE, warning=FALSE, error=FALSE}

set.seed(123432)
marat_T10_R100 <- bind_rows(replicate(100, marathon %>% sample_n(10, replace = FALSE), simplify = F), .id = "Obs")

glimpse(marat_T10_R100)

```


## 100 échantillons de taille 10 

```{r}

caract_marat_T10_R100 <-
  marat_T10_R100 %>% 
  group_by(Obs) %>% 
  summarise(moyenne = mean(V6, na.rm = TRUE),
            ecarttype = sd(V6, na.rm = TRUE)) %>% 
  mutate(Taille = factor("10"))

glimpse(caract_marat_T10_R100)

```


## 100 échantillons de taille 10 : Vérification du théorème central limite

```{r, out.width= '50%', out.height='70%', message=FALSE, warning=FALSE, error=FALSE}

esperance_moyenne <- mean(caract_marat_T10_R100$moyenne)
erreurtype <- sd(caract_marat_T10_R100$moyenne)

population_moyenne <- mean(marathon$V6)
erreurtype_calcule <- sd(marathon$V6)/sqrt(10)

tcl_T10 <- bind_cols(e_m = esperance_moyenne, mu = population_moyenne, et = erreurtype, etc = erreurtype_calcule) 

tcl_T10

```


## 100 échantillons de taille 10 - Représentation graphique

```{r, out.width= '40%', out.height='70%', message=FALSE, warning=FALSE, error=FALSE}

obslevel <- c(seq(1:100))

fig_T10_1 <-
  ggplot(caract_marat_T10_R100) +
  geom_point(aes(x = Obs, y = moyenne)) +
  geom_hline(aes(yintercept = mean(moyenne)), colour = "red") +
  geom_hline(data = marathon, aes(yintercept = mean(V6)), colour = "green") +
  scale_x_discrete(limits = obslevel) +
  theme(axis.text.x = element_text(angle = -60, hjust = 1, size = 6))

```


## 100 Échantillons de taille 10 - Représentation graphique

```{r, out.width= '50%', out.height='70%', message=FALSE, warning=FALSE, error=FALSE}

fig_T10_2 <- 
  ggplot(caract_marat_T10_R100) +
  geom_histogram(aes(x = moyenne)) +
  geom_vline(aes(xintercept = mean(moyenne)), colour = "red") +
  geom_vline(data = marathon, aes(xintercept = mean(V6)), color = "green")

```


## 100 Échantillons de taille 10 - Représentation graphique

```{r, out.width= '90%', out.height='70%', message=FALSE, warning=FALSE, error=FALSE}

library(ggpubr)

ggarrange(fig_T10_1, fig_T10_2, ncol = 2)

```


## 100 échantillons de taille 30


```{r, out.width= '50%', out.height='70%', message=FALSE, warning=FALSE, error=FALSE}

set.seed(1234)
marat_T30_R100 <- bind_rows(replicate(100, marathon %>% sample_n(30, replace = FALSE), simplify = F), .id = "Obs")

caract_marat_T30_R100 <-
  marat_T30_R100 %>% 
  group_by(Obs) %>% 
  summarise(moyenne = mean(V6, na.rm = TRUE),
            ecarttype = sd(V6, na.rm = TRUE)) %>% 
  mutate(Taille = factor("30"))

head(caract_marat_T30_R100)

```


## 100 échantillons de taille 30 : Vérification du théorème central limite

```{r, out.width= '60%', out.height='70%', message=FALSE, warning=FALSE, error=FALSE}

esperance_moyenne <- mean(caract_marat_T30_R100$moyenne)
erreurtype <- sd(caract_marat_T30_R100$moyenne)

population_moyenne <- mean(marathon$V6)
erreurtype_calcule <- sd(marathon$V6)/sqrt(30)

tcl_T30 <- bind_cols(e_m = esperance_moyenne, mu = population_moyenne, et = erreurtype, etc = erreurtype_calcule) 

tcl_T30

```

## 100 échantillons de taille 30

```{r, out.width= '60%', out.height='70%', message=FALSE, warning=FALSE, error=FALSE}

#obslevel <- c(seq(1:100))

fig_T30_1 <- 
  ggplot(caract_marat_T30_R100) +
  geom_point(aes(x = Obs, y = moyenne)) +
  geom_hline(aes(yintercept = mean(moyenne)), colour = "red") +
  geom_hline(data = marathon, aes(yintercept = mean(V6)), colour = "green") +
  scale_x_discrete(limits = obslevel) +
  theme(axis.text.x = element_text(angle = -60, hjust = 1, size = 6))

```



## 100 Échantillons de taille 30 - Représentation graphique

```{r, out.width= '60%', out.height='70%', message=FALSE, warning=FALSE, error=FALSE}

fig_T30_2 <- 
  ggplot(caract_marat_T30_R100) +
  geom_histogram(aes(x = moyenne)) +
  geom_vline(aes(xintercept = mean(moyenne)), colour = "red") +
  geom_vline(data = marathon, aes(xintercept = mean(V6)), color = "green")

```


## 100 Échantillons de taille 30 - Représentation graphique

```{r, out.width= '90%', out.height='70%', message=FALSE, warning=FALSE, error=FALSE}

ggarrange(fig_T30_1, fig_T30_2, ncol = 2)

```


## 100 échantillons de tailles 50

```{r, out.width= '60%', out.height='70%', message=FALSE, warning=FALSE, error=FALSE}

set.seed(12302)
marat_T50_R100 <- bind_rows(replicate(100, marathon %>% sample_n(50, replace = FALSE), simplify = F), .id = "Obs")

caract_marat_T50_R100 <-
  marat_T50_R100 %>% 
  group_by(Obs) %>% 
  summarise(moyenne = mean(V6, na.rm = TRUE),
            ecarttype = sd(V6, na.rm = TRUE))%>% 
  mutate(Taille = factor("50")) 

glimpse(caract_marat_T50_R100)

```

## 100 échantillons de taille 50 : Vérification du théorème central limite

```{r, out.width= '60%', out.height='70%', message=FALSE, warning=FALSE, error=FALSE}

esperance_moyenne <- mean(caract_marat_T50_R100$moyenne)
erreurtype <- sd(caract_marat_T50_R100$moyenne)

population_moyenne <- mean(marathon$V6)
erreurtype_calcule <- sd(marathon$V6)/sqrt(50)

tcl_T50 <- bind_cols(e_m = esperance_moyenne, mu = population_moyenne, et = erreurtype, etc = erreurtype_calcule) 

tcl_T50

```


## 100 échantillons de taille 50

```{r, out.width= '50%', out.height='70%', message=FALSE, warning=FALSE, error=FALSE}

ggplot(caract_marat_T50_R100) +
  geom_histogram(aes(x = moyenne)) +
  geom_point(aes(x = moyenne, y = Obs)) +
  geom_vline(aes(xintercept = mean(moyenne)), color = "red", size = 0.1) +
  geom_vline(data = marathon, aes(xintercept = mean(V6)), color = "green", size = 0.1)

```



## Comparaison de plusieurs distributions d'échantillonnage

```{r, out.width= '50%', out.height='70%', message=FALSE, warning=FALSE, error=FALSE}

fig_comp <- 
  ggplot() +
  geom_density(data = caract_marat_T10_R100, aes(x = moyenne), colour = "yellow", fill = "yellow") +
  geom_density(data = caract_marat_T30_R100, aes(x = moyenne), colour = "green") +
  geom_density(data = caract_marat_T50_R100, aes(x = moyenne), colour = "purple") +
  geom_density(data = marathon, aes(x = V6), colour = "red") +
  geom_vline(data = marathon, aes(xintercept = mean(V6)), color = "black")
  
```


## Comparaison de plusieurs distributions d'échantillonnage

```{r}

fig_comp 

```


## Fonction
Nous avons sélectionné plusieurs échantillons en répliquant la meême formule plusieurs fois. Essayons de voir si nous pouvons faire la meême chose en utilisant les fonctions.

```{r}

echantillon <- function(k, donnee, n){
  bind_rows(replicate(k, donnee %>% sample_n(n, replace = FALSE), simplify = F), .id = "Obs")

}

echantillon_t30_i100 <- echantillon(100, marathon, 30)

ech <- c("taille5", "taille6")
samp_k <- vector("list", length  = 2)       
names(samp_k) <- names(ech)
for (i in 5:6) {
 samp_k[[i]] <- echantillon(100, marathon, i)
  }


#samp <- matrix(NA, nrow = length(echantillon), ncol = 7)
#names(samp) <- names(marathon)
#for (i in 5:6) {
# samp[i, ] <- echantillon(100, marathon, i)
#  }

```


Intervalle de confiance
========================================================

## Intervalle de confiance

```{r, out.width= '50%', out.height='70%', message=FALSE, warning=FALSE, error=FALSE}

caract_marat_T30_R100 <-
  caract_marat_T30_R100 %>% 
  mutate(erreurtype = sd(marathon$V6)/sqrt(30),
         c1 = erreurtype*1.96)

head(caract_marat_T30_R100)

```


## Intervalle de confiance

```{r, out.width= '50%', out.height='70%', message=FALSE, warning=FALSE, error=FALSE}

ggplot(caract_marat_T30_R100, aes(x = Obs, y = moyenne, colour = Obs)) +
  geom_errorbar(aes(ymin = moyenne - c1, ymax = moyenne + c1), width=.2)+ 
  geom_point() +
  geom_hline(data = marathon, aes(yintercept = mean(V6)), colour = "black") +
  scale_x_discrete(limits = obslevel) +
  theme(axis.text.x = element_text(angle = -60, hjust = 1, size = 6), legend.position = "none")

```


## Intervalle de confiance

- Dans les faits, on ne connait rien sur la population, donc on va remplacer l'écart type de la population par l'écart type de l'échantillon

```{r, out.width= '50%', out.height='70%', message=FALSE, warning=FALSE, error=FALSE}

caract_marat_T30_R100
caract_marat_T30_R100 <-
  caract_marat_T30_R100 %>% 
  mutate(erreurtype_estime = ecarttype/sqrt(30),
         c1_estime = erreurtype_estime*1.96)

head(caract_marat_T30_R100)

```


## Intervalle de confiance*

```{r, out.width= '60%', out.height='70%', message=FALSE, warning=FALSE, error=FALSE}

ggplot(caract_marat_T30_R100, aes(x = Obs, y = moyenne, colour = Obs)) +
  geom_errorbar(aes(ymin = moyenne - c1_estime, ymax = moyenne + c1_estime), width=.2)+ 
  geom_point() +
  geom_hline(data = marathon, aes(yintercept = mean(V6)), colour = "black") +
  scale_x_discrete(limits = obslevel) +
  theme(axis.text.x = element_text(angle = -60, hjust = 1, size = 6), legend.position = "none")

```


## Quels sont les échantillons qui s'écartent de deux écart types de la moyenne

```{r, out.width= '60%', out.height='70%', message=FALSE, warning=FALSE, error=FALSE}

ggplot(caract_marat_T30_R100, aes(x = Obs, y = moyenne, colour = Obs)) +
  geom_point() +
  geom_hline(data = marathon, aes(yintercept = (mean(V6) - 1.96*sd(V6)/sqrt(30))), colour = "red") +
  geom_hline(data = marathon, aes(yintercept = (mean(V6) + 1.96*sd(V6)/sqrt(30))), colour = "red") +
  geom_hline(data = marathon, aes(yintercept = mean(V6)), colour = "black") +
  scale_x_discrete(limits = obslevel) +
  theme(axis.text.x = element_text(angle = -60, hjust = 1, size = 6), legend.position = "none")

```


## Problèmes avec l'échantillonnage aléatoire

- La base de sondage n'est pas toujours disponible (échantillonnage systématique)
- Très couteux et non éfficient
- Ne permet pas d'estimer les paramètres de petits groupes.
- Aussi dans les faits, cette technique n'est pratiquement jamais utilisée seule. 
- Elle est toujours combinée à plusieurs autres approches
- Par exemple, les données de `dhs_ipv_benin` utilisent une combinaison de plusieurs méthodes
  * Échantillonnage par grappe
  * Échantillonnage stratifié
  * Échantillonnage aléatoire
- Je vais vous présenter rapidement certains de ces techniques:
  - Échantillonnage stratifié
  - Échantillonnage par grappes


Échantillonnage stratifié
========================================================

## Régardons les distributions des femmes et des hommes dans la population des courreurs
- Pour changer la couleur de contenu des graphiques: https://rpubs.com/woobe/ggplot2_ref_part02

```{r, out.width= '60%', out.height='70%', message=FALSE, warning=FALSE, error=FALSE}

fig_s1 <-
  ggplot(marathon) +
  geom_histogram(aes(x = V6, fill = V2)) +
  scale_fill_brewer(palette="Set2")+ 
  labs(title = "Histogramme du Marathon de 2012",
       x = "Temps pour compléter le marathon",
       y = "Nombre de coureurs")

```


## Régardons les distributions des femmes et des hommes dans la population des courreurs

```{r, out.width= '60%', out.height='70%', message=FALSE, warning=FALSE, error=FALSE}

fig_S2 <-
  ggplot(marathon) +
  geom_histogram(aes(x = V6, fill = V2)) +
  scale_fill_brewer(palette="Set2")+ 
  facet_wrap(~V2) +
  geom_vline(aes(xintercept = mean(V6)), col = "red") +
  labs(title = "Histogramme du Marathon de 2012",
       x = "Temps pour compléter le marathon",
       y = "Nombre de coureurs")

```

## Régardons les distributions des femmes et des hommes dans la population des courreurs

```{r, out.width= '90%', out.height='70%', message=FALSE, warning=FALSE, error=FALSE}

ggarrange(fig_s1, fig_S2, ncol = 2)

```


## Combien avons-nous d'hommes et de femmes?

- La distribution des femmes peut eêtre différente de la distribution des hommes, dans ce cas, on va utiliser comme variable de stratification le sexe.

```{r, out.width= '50%', out.height='70%', message=FALSE, warning=FALSE, error=FALSE}

freq(marathon$V2)
#freq(marathon$V5)

```


## Échantillonnage stratifié

Vous pourriez préférer l'échantillonnage stratifié à l'échantillonnage aléatoire simple pour plusieurs raisons.

1. Permet d'augmenter le degré de confiance pour les généralisations à des sous-groupes ou des secteurs particuliers. 
- Cela garantit que vous pourrez représenter non seulement la population totale, mais également des sous-groupes clés de la population, en particulier les groupes minoritaires. 
- Si vous voulez pouvoir parler de sous-groupes, c’est peut-être le seul moyen de s’assurer efficacement de le faire.
- Si le sous-groupe est extrêmement petit, vous pouvez utiliser différentes fractions d'échantillonnage (f) dans les différentes strates pour sur-échantillonner de manière aléatoire le petit groupe.

## Échantillonnage stratifié

2. L'échantillonnage aléatoire stratifié a plus de précision statistique que l'échantillonnage aléatoire simple si les strates ou les groupes sont homogènes. 
- S'ils le sont, vous devez vous attendre à ce que la variabilité au sein des groupes soit inférieure à celle de la population dans son ensemble. L'échantillonnage stratifié profite de ce fait.


## Échantillonnage stratifié : Procédure


- La population est divisée en groupes homogènes et mutuellement exclusifs (strates), tels que des quartiers, puis les observations sont sélectionnées de manière aléatoire au sein de chaque strate.
- **NB:** Contrairement à l'échantillonnage par grappe, où les strates sont presque toujours spatiales, les strates sont généralement choisies pour être les facteurs de confusion de l'analyse démographique (âge, sexe, etc.) mais peuvent aussi être spatiales.
- L'objectif principal de l'échantillonnage stratifié est de réduire l'erreur d'échantillonnage.


## Échantillonnage stratifié : Exemple



Échantillonnage par grappe
========================================================


Erreur totale
========================================================

-->

